"use strict";(self.webpackChunkmy_app=self.webpackChunkmy_app||[]).push([[922],{5224:function(e,n,t){t.d(n,{z:function(){return s}});var i,a=t(168),o=(0,t(1191).ZP)("button")(i||(i=(0,a.Z)(["\n  background: ",";\n  color: ",";\n  font-size: 1rem;\n  font-weight: 700;\n  width: 100%;\n  border: 1px solid #edf3f5;\n  border-radius: 4px;\n  padding: 13px 0;\n  cursor: pointer;\n  margin-top: 0.625rem;\n  max-width: 180px;\n  transition: all 0.3s ease-in-out;\n  box-shadow: 0 16px 30px rgb(23 31 114 / 20%);\n\n  &:hover,\n  &:active,\n  &:focus {\n    color: #fff;\n    border: 1px solid rgb(255, 130, 92);\n    background-color: rgb(255, 130, 92);\n  }\n"])),(function(e){return e.color||"#2e186a"}),(function(e){return e.color?"#2E186A":"#fff"})),r=t(184),s=function(e){var n=e.color,t=e.children,i=e.onClick;return(0,r.jsx)(o,{color:n,onClick:i,children:t})}},6922:function(e,n,t){t.r(n),t.d(n,{default:function(){return ie}});var i,a,o,r,s,l,c,d,h,p,u,m,f,g,x,w,v,y=t(2791),b=JSON.parse('{"TN":"ADVANCING LANGUAGE TECHNOLOGY FOR GOOD","fL":"The Language Technology Lab is a team of researchers pushing the boundaries of natural language processing (NLP) research. Our work targets critical real-world challenges by leveraging the latest advancements in NLP and AI.","LI":[{"title":"About Us","path":"/people"},{"title":"Our Research","color":"#fff","path":"/research"}]}'),j=JSON.parse('{"TN":"Stay in Touch","fL":"For a quarterly update of our research and upcoming events, follow our offical X account.","LI":"Follow Us on X","HQ":"https://x.com/CambridgeLTL"}'),Z=t(3008),L=t(4350),k=t(9603),T=t(1758),C=t(4720),A=t(5224),P=t(168),S=t(8786),I=t(1191),z=(0,I.ZP)("section")(i||(i=(0,P.Z)(["\n  position: relative;\n  padding: 4rem 0 8rem;\n\n  @media only screen and (max-width: 1024px) {\n    padding: 4rem 0 4rem;\n  }\n"]))),N=((0,I.ZP)("p")(a||(a=(0,P.Z)(["\n  margin: 1.5rem 0 2rem 0;\n"]))),(0,I.ZP)(S.Z)(o||(o=(0,P.Z)(["\n  flex-direction: ",";\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n\n  @media only screen and (max-width: 768px) {\n    flex-direction: column; // Stack items on smaller screens\n    justify-content: center;\n    align-items: center;\n  }\n"])),(function(e){return"left"===e.direction?"row":"row-reverse"}))),O=(0,I.ZP)("div")(r||(r=(0,P.Z)(["\n  display: flex;\n  flex-direction: column;\n  justify-content: center;\n  height: 100%;\n  text-align: left;\n\n  @media only screen and (max-width: 768px) {\n    text-align: center; // Center-align text on smaller screens\n    margin-bottom: 2rem; // Add spacing between stacked items\n  }\n"]))),E=(0,I.ZP)("div")(s||(s=(0,P.Z)(["\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  height: 100%;\n\n  button {\n    margin: 0 auto;\n  }\n\n  @media only screen and (max-width: 768px) {\n    display: none; // Hide the button on screens smaller than 768px\n  }\n"]))),H=(0,I.ZP)("h6")(l||(l=(0,P.Z)(["\n  font-size: 50px;\n  margin: 0;\n  font-weight: normal;\n  padding: 0rem 0 2rem;\n\n  @media only screen and (max-width: 768px) {\n    font-size: 30px; // Reduce title size on smaller screens\n  }\n"]))),R=I.ZP.img(c||(c=(0,P.Z)(["\n  \n  width: ",";  // Default width is 100%, but it can be overridden\n  height: ",";  // Default height is 200px, but it can be overridden\n  object-fit: cover;  // Maintain aspect ratio and cover the given area\n  object-position: center;  // Center the image\n  border-radius: 5px;  // Optional: add some border-radius\n"])),(function(e){return e.width||"100%"}),(function(e){return e.height||"200px"})),M=t(4880),J=t(184),W=L.Z.Meta,F=(0,C.Z)()((function(e){var n=e.title,t=e.content,i=void 0===t?[]:t,a=e.button,o=e.t,r=e.id,s=e.fade_direction,l=(0,M.k6)();return(0,J.jsx)(z,{children:(0,J.jsx)(T.pT,{direction:s,triggerOnce:!0,children:(0,J.jsxs)("div",{children:[(0,J.jsxs)(N,{justify:"space-between",align:"middle",id:r,direction:"left",children:[(0,J.jsx)(k.Z,{lg:11,md:12,sm:24,xs:24,children:(0,J.jsx)(O,{children:(0,J.jsx)(H,{children:o(n)})})}),(0,J.jsx)(k.Z,{lg:4,md:12,sm:24,xs:24,children:a&&(0,J.jsx)(E,{children:(0,J.jsx)(A.z,{onClick:function(){return l.push(a.link)},children:a.title},"learn_more")})})]}),(0,J.jsx)(N,{justify:"space-between",align:"middle",id:r,direction:"left",gutter:[24,24],children:i.slice(0,3).map((function(e,n){return(0,J.jsx)(k.Z,{lg:8,md:12,sm:24,xs:24,children:(0,J.jsx)(L.Z,{hoverable:!0,cover:(0,J.jsx)(R,{src:e.photo?"".concat("","/img/photo/").concat(e.photo):"".concat("","/img/photo/default.jpg"),width:"100%",height:"250px",alt:e.title||"Default Photo"}),children:(0,J.jsx)(W,{title:e.title,description:e.date})})},n)}))})]})})})})),_=t(9439),D=t(5594),U=t(2419),G=(0,I.ZP)("section")(d||(d=(0,P.Z)(["\n  position: relative;\n  padding: 4rem 0 8rem;\n\n  @media only screen and (max-width: 1024px) {\n    padding: 4rem 0 4rem;\n  }\n"]))),X=(0,I.ZP)("p")(h||(h=(0,P.Z)(["\n  margin: 1.5rem 0 2rem 0;\n"]))),B=(0,I.ZP)(S.Z)(p||(p=(0,P.Z)(["\n  flex-direction: ",";\n\n  @media only screen and (max-width: 768px) {\n    flex-direction: column; // Stack columns vertically for smaller screens\n    justify-content: center;\n    align-items: center;\n  }\n"])),(function(e){return"left"===e.direction?"row":"row-reverse"})),V=(0,I.ZP)("div")(u||(u=(0,P.Z)(["\n  position: relative;\n  max-width: 540px;\n\n  @media only screen and (max-width: 575px) {\n    padding-top: 4rem;\n  }\n"]))),q=((0,I.ZP)("div")(m||(m=(0,P.Z)(["\n  display: flex;\n  justify-content: space-between;\n  max-width: 100%;\n"]))),(0,I.ZP)("h6")(f||(f=(0,P.Z)(['\n  font-size: 15px;\n  line-height: 1rem;\n  padding: 0.5rem 0;\n  text-transform: uppercase;\n  color: #000;\n  \n  font-family: "Motiva Sans Light", sans-serif;\n']))),(0,I.ZP)("p")(g||(g=(0,P.Z)(["\n  font-size: 13px;\n"]))),(0,I.ZP)("div")(x||(x=(0,P.Z)(["\n  display: flex;\n  justify-content: space-between;\n  max-width: 100%;\n\n  @media screen and (min-width: 1024px) {\n    max-width: 80%;\n  }\n\n  button:last-child {\n    margin-left: 0px;\n  }\n"])))),Q=(0,I.ZP)("h6")(w||(w=(0,P.Z)(["\n  font-size: 20px; // Adjust this value to match the button size\n  margin: 0;\n  font-weight: normal; // Adjust if needed to match the button\n"]))),Y=(0,I.ZP)("p")(v||(v=(0,P.Z)(["\n  font-size: 20px; // Adjust this value to match the button size\n  margin: 0;\n  font-weight: normal; // Adjust if needed to match the button\n"]))),K=(0,C.Z)()((function(e){var n=e.title,t=e.content,i=void 0===t?[]:t,a=e.instruction,o=(e.button,e.t),r=e.id,s=e.direction,l=e.fade_direction,c=i.length>0?i[1]:null,d=(0,y.useState)(!1),h=(0,_.Z)(d,2),p=h[0];h[1];return(0,J.jsx)(G,{children:(0,J.jsx)(T.pT,{direction:l,triggerOnce:!0,children:(0,J.jsx)("div",{children:(0,J.jsxs)(B,{justify:"space-between",align:"middle",id:r,direction:s,children:[(0,J.jsx)(k.Z,{lg:12,md:11,sm:12,xs:24,children:(0,J.jsx)(V,{children:c&&(0,J.jsx)(D.Z.Ribbon,{text:c.venue,children:(0,J.jsxs)(L.Z,{size:"small",children:[(0,J.jsx)(Q,{style:{maxWidth:"90%"},children:c.title}),(0,J.jsxs)(U.Z,{placement:"right",color:"#18216d",title:c.bio,overlayStyle:{maxWidth:"900px"},showArrow:!1,children:["                    ",(0,J.jsx)(Y,{children:c.speaker+" ("+c.affiliation+")"})]}),(0,J.jsx)(Y,{children:c.time+", "+c.date}),c.place&&(0,J.jsx)(Y,{children:"Where: "+c.place}),(0,J.jsx)(Y,{children:p&&"Abstract: "+c.abstract}),(0,J.jsx)(q,{children:c.link&&(0,J.jsx)(A.z,{onClick:function(){return window.open(c.link,"_blank")},children:"Join Zoom Meeting"})})]})})})}),(0,J.jsx)(k.Z,{lg:11,md:11,sm:11,xs:24,children:(0,J.jsxs)(V,{children:[(0,J.jsx)("h6",{children:o(n)}),(0,J.jsx)(X,{children:a})]})})]})})})})})),$=t(4260),ee=(0,y.lazy)((function(){return t.e(279).then(t.bind(t,6281))})),ne=(0,y.lazy)((function(){return Promise.resolve().then(t.bind(t,2478))})),te=(0,y.lazy)((function(){return t.e(69).then(t.bind(t,8290))})),ie=function(){return(0,J.jsxs)(ne,{children:[(0,J.jsx)(te,{direction:"right",title:b.TN,content:b.fL,button:b.LI,icon:"group_1_zoomed.jpg",id:"home",fade_direction:"up"}),(0,J.jsx)(F,{title:"Highlights",content:Z,id:"highlight",fade_direction:"up",button:{link:"/news",title:"More Highlights"}}),(0,J.jsx)(K,{title:"LTL Seminars",content:$,id:"seminar",direction:"left",fade_direction:"up",instruction:"LTL seminars are held every Thursday during term time, either in person at the English Faculty Building or online. Some in-person seminars may also offer a hybrid option for remote participation. We welcome attendees from the University and the wider public."}),(0,J.jsx)(ee,{title:j.TN,content:j.fL,button:j.LI,url:j.HQ})]})}},3008:function(e){e.exports=JSON.parse('[{"type":"events","title":"LTL @ CHIA Conference","text":"LTL has been invited to present at the CHIA Conference. We are excited to share our research to the world!","photo":"chia_presentation.jpeg","link":"","date":"2024-10-01"},{"type":"events","title":"LTL @ EMNLP 2023","text":"Please find attached a selection of group photos of LTL at the EMNLP 2023 Conference in Singapore! ","photo":"ltl_emnlp_group.jpg","link":"","date":"2023-12-09"},{"type":"events","title":"LTL Halloween Party","text":"What a fun night at our Halloween party have a look at the pumpkin carving competition entries!","photo":"halloween.jpeg","link":"https://x.com/CambridgeLTL/status/1587754105191239680","date":"2021-08-02"},{"type":"news","title":"LTL Welcome Party","text":"Welcome our new incoming students to join LTL! Welcome our new incoming students to join LTL!","photo":"people_small.jpg","link":"","date":"2024-10-01"}]')},4260:function(e){e.exports=JSON.parse('[{"type":"seminar","title":"Generative AI for Science","speaker":"Greg Durrett","affiliation":"UT Austin Computer Science","link":"https://cam-ac-uk.zoom.us/j/97599459216?pwd=QTRsOWZCOXRTREVnbTJBdXVpOXFvdz09","venue":"online","place":"","date":"Thursday, 6 June 2024","time":"3 pm - 4 pm","abstract":"This talk will explore how we can develop and use generative AI to help researchers and clinicians. I will first discuss how LLMs can act as research co-advisors. Then I will present Dragonfly, our new architecture for large visual-language model that leverages multi-resolution Zoom to achieve state-of-the-art performance across several medical tasks. Finally, I will explore the role of language as the foundational data modality for science.","bio":"James Zou is an associate professor of Biomedical Data Science, CS, and EE at Stanford University. He is also the faculty director of Stanford AI4Health. He works on improving the foundations of ML by making models more trustworthy and reliable, as well as in-depth scientific and clinical applications. Many of his innovations are widely used in tech and biotech industries.  He has received a Sloan Fellowship, an NSF CAREER Award, two Chan-Zuckerberg Investigator Awards, a Top Ten Clinical Achievement Award, several best paper awards, and faculty awards from Google, Amazon, Tencent, and Adobe. His research has also been profiled in popular press, including the NY Times, WSJ, and WIRED."},{"type":"seminar","title":"Generative AI for Science","speaker":"James Zou","affiliation":"Stanford University","link":"https://cam-ac-uk.zoom.us/j/97599459216?pwd=QTRsOWZCOXRTREVnbTJBdXVpOXFvdz09","venue":"online","place":"","date":"Thursday, 6 June 2024","time":"3 pm - 4 pm","abstract":"This talk will explore how we can develop and use generative AI to help researchers and clinicians. I will first discuss how LLMs can act as research co-advisors. Then I will present Dragonfly, our new architecture for large visual-language model that leverages multi-resolution Zoom to achieve state-of-the-art performance across several medical tasks. Finally, I will explore the role of language as the foundational data modality for science.","bio":"James Zou is an associate professor of Biomedical Data Science, CS, and EE at Stanford University. He is also the faculty director of Stanford AI4Health. He works on improving the foundations of ML by making models more trustworthy and reliable, as well as in-depth scientific and clinical applications. Many of his innovations are widely used in tech and biotech industries.  He has received a Sloan Fellowship, an NSF CAREER Award, two Chan-Zuckerberg Investigator Awards, a Top Ten Clinical Achievement Award, several best paper awards, and faculty awards from Google, Amazon, Tencent, and Adobe. His research has also been profiled in popular press, including the NY Times, WSJ, and WIRED."},{"type":"seminar","title":"Practical and Specialised NLP Solutions: The Case of Social Media","speaker":"Jose Camacho-Collados","affiliation":"Cardiff University.","link":"https://cam-ac-uk.zoom.us/j/97599459216?pwd=QTRsOWZCOXRTREVnbTJBdXVpOXFvdz09","venue":"hybrid","place":"Room SR-24 in the English Faculty Building","date":"Thursday, 30 May 2024","time":"3 pm - 4 pm","abstract":"Large generative language models (LLMs) are currently ubiquitous in NLP research. However, when it comes to specific applications, these powerful models are often impractical and not always the optimal choice, and there may be more adequate solutions for specific problems. In this talk, I will advocate for practical and effective solutions in NLP. I will try to revisit the importance of high-quality data (including labelled data) and reliable evaluation benchmarks in the current LLM landscape. Using social media as a case study, I will explain some of the challenges arising from processing content in these platforms. The multilingual, dynamic, informal and multimodal nature of social media, as well as the constant influx of new content, means that standard techniques are seldom optimal, and specialised models are often required.","bio":"Jose Camacho-Collados is a Professor at Cardiff University, leading the Cardiff NLP group. Before joining Cardiff University, he completed his PhD in Sapienza University of Rome and was a Google AI PhD Fellow. Until recently, his research has focused on various semantics aspects in NLP with a distributional perspective. He wrote the \u201cEmbeddings in Natural Language Processing\\" book and is the General Chair of *SEM 2024. More related to the topic of the talk, in the last few years Jose has been working in social media analysis and applications, developing NLP tools specifically targeted to this domain."}]')}}]);
//# sourceMappingURL=922.2685b61d.chunk.js.map