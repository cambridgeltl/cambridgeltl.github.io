[
  {
    "title": "Fine-Grained Multilingual Dialogue Evaluation",
    "abstract": "Dialogue evaluation aims to answer the question: how well does a dialogue system perform? Existing evaluation approaches fall into two main categories: human evaluation and automatic metrics.\n\nHuman evaluation is often considered the gold standard due to its ability to capture the holistic context of dialogues. However, it comes with significant disadvantages, including inconsistency, high cost, and logistical challenges. On the other hand, automatic evaluation metrics are faster, cheaper, and more reproducible but often fail to correlate with human judgment. \n\nDialogue quality is inherently multi-faceted, requiring assessments across various fine-grained dimensions. Breaking down overall quality into specific evaluation dimensions (e.g., grammaticality, coherence, and informativeness) helps reduce subjectivity and provides actionable insights for system improvement. For multilingual dialogues, evaluation dimensions have to consider linguistic and cultural contexts, with both additional granularity and new perspectives.\n\nThis project aims to advance fine-grained multilingual dialogue evaluation by:\n 1) Identifying key dimensions of dialogue quality across multiple languages and cultural contexts.\n 2) Proposing linguistically motivated, fine-grained evaluation protocols for human annotation.\n 3) Developing methods to improve consistency and inter-annotator agreement in multilingual dialogue evaluations.\n 4) Exploring the potential of extending human evaluation protocols to automatic metrics, leveraging large language models (LLMs).",
    "references": [
      {
        "text": "Bandalos, D. L. (2018). Measurement theory and applications for the social sciences. Sections 1–6. Guilford Publications.",
        "link": "https://www.soc.univ.kiev.ua/sites/default/files/library/elopen/methodology_in_the_social_sciences_deborah_l._bandalos_-_measurement_theory_and_applications_for_the_social_sciences-the_guilford_press_2018.pdf"
      },
      {
        "text": "Mehri et al., 2022. Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges.",
        "link": "https://arxiv.org/abs/2203.10012"
      },
      {
        "text": "Hu, S., Wang, X., Yuan, M., Korhonen, A., & Vulic, I. 2024. DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models. In Proceedings of the 2024 NAACL-HLT (Volume 3: System Demonstrations), Mexico City, Mexico.",
        "link": "https://aclanthology.org/2024.naacl-demo.4/"
      }
    ],
    "contacts": [
      "Songbo Hu (sh2091@cam.ac.uk)"
    ],
    "category": "C"
  },
  {
    "title": "Probing pre-trained language models for specialist knowledge",
    "abstract": "Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs) [5]. Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored. To this end, we have proposed a contrastive probing approach [1] that can well address the multi-token issue existing in biomedical knowledge probing tasks. Our initial findings [1] indicate that the real lower bound on the amount of factual knowledge encoded by PLMs is higher than we estimated. Meanwhile, prompt-based probing approaches such as AutoPrompt [3], SoftPrompt [4] and OptiPrompt [5] have been investigated for further improving such lower bound with additional labelled data for fine-tuning prompts. In this project, we will continue to analyse and improve our estimation of the lower bound by optimising both the encoding space (e.g. using our self-supervised contrastive learning technique [1]) and the input space (e.g. using the prompt optimising techniques) [2-4].",
    "references": [
      {
        "text": "Zaiqiao Meng, Fangyu Liu, Ehsan Shareghi, Yixuan Su, Charlotte Collins, Nigel Collier. Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models",
        "link": "https://arxiv.org/abs/2110.08173"
      },
      {
        "text": "Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. 2020a. Auto-prompt: Eliciting knowledge from language models with automatically generated prompts.",
        "link": "https://aclanthology.org/2020.emnlp-main.346/"
      },
      {
        "text": "Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying LMS with mixtures of soft prompts.",
        "link": "https://aclanthology.org/2021.naacl-main.410/"
      },
      {
        "text": "Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021. Factual probing is [mask]: Learning vs. learning to recall.",
        "link": "https://aclanthology.org/2021.naacl-main.398/"
      },
      {
        "text": "Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowledge bases?",
        "link": "https://aclanthology.org/D19-1250/"
      }
    ],
    "contacts": [
      "Nigel Collier (nhc30@cam.ac.uk)",
      "Zaiqiao Meng (zm324@cam.ac.uk)"
    ],
    "category": "A"
  },
  {
    "title": "Identifying focal geographic locations in news event reports",
    "abstract": "News event reports contain many location identifiers including the name of the place where the event is occurring, but also other locations such as a victim's country of origin and where they have travelled through, the location of the reporting organisation, the location of agencies, as well as demonyms identifying people involved in the event. Locations are reported at various levels of granularity such as country, province, city and town depending on the assumed readership of the news report. The goals of this work are: (a) to look through a sample of GeoWebNews data (https://github.com/milangritta/Pragmatic-Guide-to-Geoparsing-Evaluation), and to use this to produce a gold standard for evaluation; (b) to survey what is already known about the challenge of identifying location entities (toponyms) in the text (e.g. see Milan Gritta's published works as a starting point); (c) to use state of the art tools (e.g. SpaCy, FLAIR) to perform named entity recognition for locations on the document, possibly linking entities to geographic coordinates as an extension; (d) to develop a classifier to identify focal locations for events (if the news report does report an event); (e) to identify categories of errors in the outputs of the state of the art classifier; (f) suggest improved strategies based on what you have learnt.",
    "references": [
      {
        "text": "Gritta, M., Pilehvar, M. T., Limsopatham, N., & Collier, N. (2018). What’s missing in geographical parsing?",
        "link": "https://link.springer.com/article/10.1007/s10579-017-9385-8"
      },
      {
        "text": "Gritta, M., Pilehvar, M. T., & Collier, N. (2020). A pragmatic guide to geoparsing evaluation.",
        "link": "https://link.springer.com/article/10.1007/s10579-019-09475-3"
      },
      {
        "text": "Gritta, M. (2019). Where are you talking about? advances and challenges of geographic analysis of text with application to disease monitoring.",
        "link": "https://www.repository.cam.ac.uk/items/6915c499-6c6e-4123-ad3c-9e37de65e6a5"
      },
      {
        "text": "Gritta, M., Pilehvar, M. T., Limsopatham, N., & Collier, N. (2017, July). Vancouver welcomes you! Minimalist location metonymy resolution.\n",
        "link": "https://aclanthology.org/P17-1115/"
      }
    ],
    "contacts": [
      "Nigel Collier (nhc30@cam.ac.uk)"
    ],
    "category": "B"
  },
  {
    "title": "Typology of subjects from Universal Dependencies",
    "abstract": "The notion of \"subject\" has been debated for long, and yet its exact definition is still an open research question: cross-lingually, subjects vary their position with respect to the verb and the object, their morphosyntactic alignment, their anaphoric reductions based on the transitivity of the verb and the range of constructions they may appear in. In the past, quantitative linguistic studies on subject typology were hindered by the lack of syntactic annotation in large multilingual corpora. Now the Universal Dependencies can provide the annotations. The student will perform a quantitative analysis of subjects and their properties (animacy, position, topicality, etc.) within this resource and will look for interesting cross-lingual correlations.",
    "references": [
    ],
    "contacts": [
      "Edoardo Ponti (ep490@cam.ac.uk)",
      "Anna Korhonen (alk23@cam.ac.uk)"
    ],
    "category": "C"
  }
]
